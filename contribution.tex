In this paper we propose the Efficient-UCB-Variance (henceforth referred to as EUCBV) algorithm for the stochastic MAB setting. EUCBV combines the approach of UCB-Improved, CCB \cite{liu2016modification} and UCBV algorithms. EUCBV by virtue of taking into account the empirical variance of the arms performs significantly better than the existing algorithms in the stochastic MAB setting. EUCBV outperforms UCBV \cite{audibert2009exploration} which also takes into account empirical variance but is less powerful than EUCBV because of the usage of exploration regulatory factor and arm elimination parameter by EUCBV. Also we carefully design the confidence interval term with the variance estimates along with the pulls allocated to each arm to balance the risk of eliminating the optimal arm against excessive optimism.   Theoretically we refine the analysis of \cite{auer2010ucb} and prove that for $T\geq K^{2.4}$ our algorithm is order optimal and enjoys a worst case gap-independent regret bound of $O\left( \sqrt{KT} \right)$ same as that of MOSS and OCUCB and better than UCBV, UCB1 and UCB-Improved. Also the gap-dependent regret bound of EUCBV is better than UCB1, UCB-Improved and MOSS but is poorer than OCUCB. However, EUCBV's gap-dependent bound matches OCUCB in the worst case scenario when all the gaps are equal. Through our theoretical analysis we establish the exact values of the exploration parameters for the best performance of EUCBV. Our proof technique is highly generic and can be easily extended to other MAB settings. An illustrative table containing the bounds is provided in Table \ref{tab:comp-bds}. 


\begin{table}
\caption{Regret upper bound of different algorithms}
\label{tab:comp-bds}
\begin{center}
\begin{tabular}{p{6em}p{12em}p{10em}}
\toprule
Algorithm  & Gap-Dependent & Gap-Independent \\
\hline
EUCBV		& $O\left( \dfrac{K\log (T\Delta^2 /K)}{\Delta}\right)$ & $O\left(\sqrt{KT}\right)$\\
UCB1        & $O\left( \dfrac{K\log T}{\Delta} \right)$ & $O\left(\sqrt{KT\log T}\right)$ \\%\midrule
UCBV        & $O\left( \dfrac{K\sigma_{\max}^{2}\log T}{\Delta} \right)$ & $O\left(\sqrt{KT\log T}\right)$ \\
UCB-Imp 		& $O\left( \dfrac{K\log (T\Delta^2)}{\Delta} \right)$ & $O\left(\sqrt{KT\log K}\right)$ \\%\midrule
MOSS	     	& $O\left( \dfrac{K^2\log (T\Delta^2 /K)}{\Delta}\right)$ & $O\left(\sqrt{KT}\right)$\\%\midrule
OCUCB     	& $O\left( \dfrac{K\log (T/ H_{i})}{\Delta}\right)$ & $O\left(\sqrt{KT}\right)$\\\midrule
\end{tabular}
\end{center}
\vspace*{-2em}
\end{table}


Empirically we show that EUCBV owing to its estimating the variance of the arms performs significantly better than MOSS, OUCUB, UCB-Improved, UCB1, UCBV, Thompson Sampling, Bayes-UCB, DMED, KL-UCB and Median Elimination algorithms. Note that except UCBV all the aforementioned algorithms do not take into account the empirical variance estimates of the arms. Also EUCBV is the first arm-elimination algorithm that takes into account the variance estimates of the arm for minimizing cumulative regret and thereby answers an open question raised by \cite{auer2010ucb}. In \cite{auer2010ucb} the authors conjectured that an UCB-Improved like arm-elimination algorithm can greatly benefit by taking into consideration the variance of the arms. Also it is the first algorithm that follows the same proof technique of UCB-Improved and achieves a gap-independent regret bound of $O\left( \sqrt{KT} \right)$ thereby closing the gap of UCB-Improved \cite{auer2010ucb} which achieved a gap-independent regret bound of $O\left( \sqrt{KT\log K} \right)$. 
	
	The rest of the paper is organized as follows. In Section~\ref{sec:eucbv} we present the  EUCBV algorithm. Our main theoretical results are stated in Section~\ref{sec:results}, while the proofs are established in   section \ref{sec:proofTheorem}. Section~\ref{sec:expt} contains results and discussions from our numerical experiments. Finally, we draw our conclusions in section \ref{sec:conc} and discuss about future works.
	
	
	