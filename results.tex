

We present below the main theorem of the paper which establishes the regret upper bound for the EUCBV  algorithm. 
\subsection*{Main Theorem}
\begin{theorem}[\textbf{\textit{Gap-dependent bound}}]
\label{Result:Theorem:1}
For $T\geq K^{2.4}$, $\rho=\frac{1}{2}$ and $\psi=\frac{T}{K^2}$, the regret $R_T$ for EUCBV satisfies
%\begin{align*}
% \E [R_{T}] \leq &\sum\limits_{i\in \A :\Delta_{i} > b}\bigg\lbrace\bigg(\dfrac{C_{1}(\rho)T^{1-\rho}}{\Delta_{i}^{2\rho -1}}\bigg) + \bigg(\Delta_{i}+\dfrac{32\log{(\psi  T\Delta_{i}^{4})}}{\Delta_{i}}\bigg) + \bigg(\dfrac{ C_{2}(\rho) T^{1-\rho}}{\Delta_{i}^{2\rho-1}} \bigg)\bigg \rbrace \\ 
% %%%%%%%%%%%%%%%%
%  & +\sum\limits_{i\in \A :0 < \Delta_{i}\leq b}\bigg(\dfrac{C_{2}(\rho)T^{1-\rho}}{b^{2\rho -1}} \bigg) + \max_{i\in \A :0 < \Delta_{i}\leq b}\Delta_{i}T
%\end{align*}
\begin{align*}
\E [R_{T}] \leq &\sum\limits_{i\in \A :\Delta_{i} > b}\bigg\lbrace 64 K + \bigg(\Delta_{i}+\dfrac{64\log{(\frac{T\Delta_{i}^{2}}{K})}}{\Delta_{i}}\bigg)\bigg \rbrace\\ 
  & +\sum\limits_{i\in \A :0 < \Delta_{i}\leq b} 32 K + \max_{i\in \A :0 < \Delta_{i}\leq b}\Delta_{i}T  
\end{align*}

for all $b\geq\sqrt{\frac{e}{T}}$. 
%In the above, $C_1(x) = \frac{2^{2+6x}.9^{x}}{\psi^{x}}$ and $C_2(x) = \frac{2^{\frac{x}{2}+\frac{19}{4}}.3^{x+\frac{1}{2}}}{\psi^{x}}$.
\end{theorem}

\begin{proof}
The proof comprises of three modules. In the first module we prove the necessary conditions for arm elimination within a specified number of rounds, which is motivated by the technique in \cite{auer2010ucb}. We first refine the proof while breaking down the confidence interval by using Lemma  \ref{proofTheorem:Lemma:1}. Then we combine the approach of \citet{audibert2009exploration} with that of  \citet{auer2010ucb} for removing the estimated variance factor in the confidence interval term for an arm $i$. Note that even though \citet{audibert2009exploration} uses Bernstein inequality to obtain the  bound, we use Chernoff-Hoeffding bound. This is because of our choice of $\rho$ which has to be $\frac{1}{2}$ or it may lead to a regret polynomial in $T$ and usage of Bernstein inequality will force the $\rho$ to take a value higher than $1$. The second module bounds the number of pulls required if an arm is eliminated on or before a particular number of rounds. Note that the number of pulls allocated in a round $m$ for each arm is $n_{m}:=\bigg\lceil\frac{\log{(\psi T\epsilon_{m}^{2})}}{2\epsilon_{m}}\bigg\rceil$ which is much lower than the pulls of each arm required by UCB-Improved or Median-Elimination. The third module deals with bounding the regret given a sub-optimal arm eliminates the optimal arm. The detailed proof is given in Section \ref{sec:proofTheorem:Theorem1}.
\end{proof}

%Next, we specialize the result of Theorem \ref{Result:Theorem:1} in Corollary \ref{Result:Corollary:1} and Corollary \ref{Result:Corollary:2}.

%\subsection{Corollary 1}
%\begin{corollary}[\textbf{\textit{Gap-dependent bound}}]
%\label{Result:Corollary:1}
%With $\psi=\frac{T}{K^2}$ and $\rho=\frac{1}{2}$, we have the following gap-dependent bound for the regret of EUCBV:
%\begin{align*}
%\E [R_T] & \sum_{i\in \A:\Delta_{i} > b}\bigg\lbrace 96 K + \dfrac{64\log{(\dfrac{T\Delta_{i}^{2}}{ K})}}{\Delta_{i}}\bigg\rbrace 
% + \max\limits_{i\in \A:\Delta_{i}\leq b}\Delta_{i}T 
%	\end{align*} 
%\end{corollary}
%\begin{proof}
%The proof is given in Section \ref{sec:proofTheorem:Corollary1}.
%\end{proof}

Thus, we clearly see that the most significant term in the gap-dependent bound is of the order $O\left(\dfrac{K\log{(T\Delta^{2}/K)}}{\Delta}\right)$ and it is better than UCB1, UCBV, MOSS and UCB-Improved. In \citet{audibert2010best} the authors define the term $H_1=\sum_{i=1}^{K}\frac{1}{\Delta_i^2}$ as the hardness of a problem and in \citet{bubeck2012regret} the authors conjectured that the gap-dependent regret upper bound can match the quantity of $O\left(\dfrac{K\log{(T/H_1)}}{\Delta}\right)$. But \citet{lattimore2015optimally} proved that the gap-dependent regret bound cannot be lower than $O\left(\sum_{i=2}^{K}\frac{\log\left(T/H_i\right)}{\Delta_i}\right)$, where $H_i=\sum_{j=1}^{K}\min\lbrace \frac{1}{\Delta_i^2},\frac{1}{\Delta_j^2}\rbrace$ and only in the worst case scenario, when all the gaps are equal then $H_1=H_{i}=\sum_{i=1}^{K}\frac{1}{\Delta^2}$. In such a scenario the EUCBV gap-dependent bound of $O\left(\dfrac{K\log{(T\Delta^{2}/ K)}}{\Delta}\right)$ reduces to $O\left(\dfrac{K\log{(T/H_1)}}{\Delta}\right)$ and hence matches the gap-dependent bound of OCUCB.

Next, we specialize the result of Theorem \ref{Result:Theorem:1} in Corollary \ref{Result:Corollary:1} to  obtain the gap-independent worst case regret. %and Corollary \ref{Result:Corollary:2}.


%\subsection*{Corollary 1}

\begin{corollary}[\textbf{\textit{Gap-independent bound}}]
\label{Result:Corollary:1}
With $\psi=\frac{T}{K^2}$, $\rho=\frac{1}{2}$ and substituting $\Delta_i =\Delta = \sqrt{\frac{K\log K}{T}}, \forall i\in \A$, we have the following gap-independent bound for the regret of EUCBV:
\begin{align*}
\E[R_{T}] & \leq 96 K^2 + 64\sqrt{KT}
	\end{align*} 
\end{corollary}
%\begin{proof}
%The proof is given in Section \ref{sec:proofTheorem:Corollary2}.
%\end{proof}

\begin{proof}
\label{Proof:Corollary:1}
In the non-stochastic scenario \cite{auer2002nonstochastic} showed that the bound on the cumulative regret can be $O\left(\sqrt{KT\log K}\right)$. But UCB1 suffered from a regret of order of  $O\left(\sqrt{KT\log T}\right)$  which is clearly improvable. Also we know from \citet{bubeck2011pure} that the function $x\in [0,1]\mapsto x\exp(-Cx^2)$ is  decreasing on $\left[\frac{1}{\sqrt{2C}},1\right ]$ for any $C>0$. So, we take $C=\left\lfloor \frac{T}{e}\right\rfloor$ and choose  $\Delta_{i}=\Delta=\sqrt{\frac{K\log K}{T}}>\sqrt{\frac{e}{T}}$ for all ${i:i\neq *}\in \A $.

	We again recall the result of Theorem \ref{Result:Theorem:1} below, 
	
\begin{align*}
\E [R_{T}] \leq &\sum\limits_{i\in \A :\Delta_{i} > b}\bigg\lbrace 64 K + \bigg(\Delta_{i}+\dfrac{64\log{(\frac{T\Delta_{i}^{2}}{K})}}{\Delta_{i}}\bigg)\bigg \rbrace\\ 
  & +\sum\limits_{i\in \A :0 < \Delta_{i}\leq b} 32 K + \max_{i\in \A :0 < \Delta_{i}\leq b}\Delta_{i}T  
\end{align*}


Substituting the parameter values $\psi=\frac{T}{K^2}$ and $\rho=\frac{1}{2}$ in the result of above Theorem \ref{Result:Theorem:1} we get,
	
	\begin{align*}
	\sum_{i\in \A :\Delta_{i} > b}\dfrac{32\log{(\psi T\Delta_{i}^{4})}}{\Delta_{i}} = \dfrac{32K\sqrt{T}\log{(T^{2}\dfrac{K^{2}(\log K)^{2}}{T^{2} K^2})}}{\sqrt{K\log K}} &\leq  \dfrac{64\sqrt{KT}\log{(\log K)}}{\sqrt{\log K}}\\
	&\overset{(a)}{\leq} 64\sqrt{KT} 
	\end{align*}		
	
 	
	Where $(a)$ happens because $\dfrac{\log{(\log K)}}{\sqrt{\log K}}\leq 1$ for $K\geq 2$. So, the total worst case gap-independent bound cannot be worse than,
	
	\begin{align*}
	\E[R_{T}]\leq 96 K^2 + 64\sqrt{KT}
	\end{align*}		
\end{proof}


Here, in the gap-independent bound of EUCBV the most significant term is $O\left(\sqrt{KT}\right)$ which exactly matches the upper bound of MOSS and OCUCB and is better than UCB-Improved, UCB1 and UCBV.
