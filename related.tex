%There has been a significant amount of research in the area of stochastic MABs. One of the earliest work can be traced to \citet{thompson1933likelihood}, which deals with  the problem of choosing between two treatments to administer on patients who come in sequentially. Other seminal works include that of  \citet{robbins1952some} and then that of \citet{lai1985asymptotically} which established an asymptotic lower bound for the cumulative regret. It showed that for any consistent allocation strategy, we can have
%$\liminf_{T \to \infty}\frac{\E[R_{T}]}{\log T}\geq\sum_{\{i:r_{i}<r^{*}\}}\frac{(r^{*}-r_{i})}{D(Q_{i}||Q^{*})},$
%where $D(Q_{i}||Q^{*})$ is the Kullback-Leibler divergence between the reward densities $Q_{i}$ and $Q^{*}$, corresponding to arms with mean $r_{i}$ and $r^{*}$, respectively.

	Bandit problems has been extensively studied in several earlier work such as \citet{thompson1933likelihood}, \citet{robbins1952some} and \citet{lai1985asymptotically} which established an asymptotic lower bound for the cumulative regret. Over the years stochastic MABs has seen several algorithms with strong regret guarantees. For  further reference an interested reader can look into \citet{bubeck2012bandits}. The upper confidence bound algorithms balance the exploration-exploitation dilemma by carefully tracking the uncertainty in estimates. One of the earliest among these algorithms is UCB1 \citep{auer2002finite}, which has a gap-dependent regret upper bound of  $O\left(\frac{K\log T}{\Delta}\right)$, where $\Delta = \min_{i:\Delta_i>0} \Delta_i$. This result is asymptotically order-optimal for the class of distributions considered. But, the worst case gap-independent regret bound of UCB1 is found to be  $O \left(\sqrt{KT\log T}\right)$. In the later work of \citet{audibert2009minimax}, the authors propose the MOSS algorithm and showed that the worst case gap-independent regret bound of MOSS is $O\left( \sqrt{KT} \right)$ which improves upon UCB1 by a factor of order $\sqrt{\log T}$. However, the gap-dependent regret of MOSS is $O\left( \frac{K^{2}\log\left(T\Delta^{2}/K\right)}{\Delta}\right)$ and in certain regimes, this can be worse than even UCB1 (see \citet{audibert2009minimax,lattimore2015optimally}). The UCB-Improved algorithm, proposed in \citet{auer2010ucb}, is a round-based algorithm\footnote{An algorithm is \textit{round-based} if it pulls all the arms equal number of times in each round and then eliminates one or more arms that it deems  to be sub-optimal.} variant of UCB1 that 
has a gap-dependent regret bound of $O\left(\frac{K\log T\Delta^{2}}{\Delta}\right)$, which is better than that of UCB1. On the other hand, the worst case gap-independent regret bound of UCB-Improved is $O\left(\sqrt{KT\log K}\right)$. Recently in \citet{lattimore2015optimally}, the authors showed that  the algorithm OCUCB achieves order-optimal gap-dependent regret bound of $O\left(\sum_{i=2}^{K}\frac{\log\left(T/H_i\right)}{\Delta_i}\right)$ where $H_i=\sum_{j=1}^{K}\min\lbrace \frac{1}{\Delta_i^2},\frac{1}{\Delta_j^2}\rbrace$ and gap-independent regret bound of $O\left( \sqrt{KT}\right)$. But OCUCB does not take into account the variance of the arms and we show that our algorithm outperforms OCUCB in all the environments considered. 

	We must also mention about UCBV \citep{audibert2009exploration} algorithm which is quite different  from the above algorithms owing to its utilization of variance estimates. UCBV has a gap-dependent regret bound of $O\left(\frac{K\sigma_{\max}^{2}\log T}{\Delta}\right)$, where $\sigma_{\max}^{2}$ denotes the maximum variance among all the arms $i\in \A$. Its gap-independent regret bound can be inferred to be same as that of UCB1 i.e $O \left(\sqrt{KT\log T}\right)$. Empirically, \citet{audibert2009exploration} showed that UCBV outperforms UCB1 in several scenarios. 
	
	Another notable design principle which has recently gained a lot of popularity is the Thompson Sampling (TS) \citep{thompson1933likelihood}, \citep{agrawal2011analysis} algorithm and Bayes-UCB (BU) algorithm \citep{kaufmann2012bayesian} which employs the Bayesian approach in solving the MAB problem. The TS algorithm samples actions according to the posterior probability that they are optimal. Even though TS is found to perform superbly in the Bernoulli Distribution but it is a known fact that when Gaussian priors are used the worst case regret can be as bad as $\Omega \left( \sqrt{KT\log T}\right)$ \citep{lattimore2015optimally}.
	
	The final design principle we will state is the information theoretic approach of the DMED \citep{honda2010asymptotically} and KL-UCB \citep{garivier2011kl} algorithms. The algorithm KL-UCB uses Kullbeck-Leibler divergence to compute the upper confidence bound for the arms. KL-UCB is stable for a short horizon and is known to reach the \citet{lai1985asymptotically} lower bound in the special case of Bernoulli Distribution. But \citet{garivier2011kl} showed that KL-UCB, MOSS and UCB1 algorithms are  empirically outperformed by UCBV in the exponential distribution as they do not take the variance of the arms into consideration. 