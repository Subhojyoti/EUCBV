%There has been a significant amount of research in the area of stochastic MABs. One of the earliest work can be traced to \citet{thompson1933likelihood}, which deals with  the problem of choosing between two treatments to administer on patients who come in sequentially. Other seminal works include that of  \citet{robbins1952some} and then that of \citet{lai1985asymptotically} which established an asymptotic lower bound for the cumulative regret. It showed that for any consistent allocation strategy, we can have
%$\liminf_{T \to \infty}\frac{\E[R_{T}]}{\log T}\geq\sum_{\{i:r_{i}<r^{*}\}}\frac{(r^{*}-r_{i})}{D(Q_{i}||Q^{*})},$
%where $D(Q_{i}||Q^{*})$ is the Kullback-Leibler divergence between the reward densities $Q_{i}$ and $Q^{*}$, corresponding to arms with mean $r_{i}$ and $r^{*}$, respectively.

	Over the years stochastic MABs has seen several algorithms with strong regret guarantees. For  further reference an interestetd reader can look into \citet{bubeck2012bandits}. In this section we will exclusively focus on upper confidence bound algorithms that balance the exploration-exploitation dilemma by carefully tracking the uncertainty in estimates. One of the earliest among these algorithms is UCB1 \citep{auer2002finite}, which has a gap-dependent regret upper bound of  $O\left(\frac{K\log T}{\Delta}\right)$, where $\Delta = \min_{i:\Delta_i>0} \Delta_i$. This result is asymptotically order-optimal for the class of distributions considered. But, the worst case gap-independent regret bound of UCB1 is found to be  $O \left(\sqrt{KT\log T}\right)$. In the later work of \citet{audibert2009minimax}, the authors propose the MOSS algorithm and showed that the worst case gap-independent regret bound of MOSS is $O\left( \sqrt{KT} \right)$ which improves upon UCB1 by a factor of order $\sqrt{\log T}$. However, the gap-dependent regret of MOSS is  $O\left( \frac{K^{2}\log\left(T\Delta^{2}/K\right)}{\Delta}\right)$ and in certain regimes, this can be worse than even UCB1 (see \citet{audibert2009minimax,lattimore2015optimally}). The UCB-Improved algorithm, proposed in \citet{auer2010ucb}, is a round-based algorithm\footnote{An algorithm is \textit{round-based} if it pulls all the arms equal number of times in each round and then eliminates one or more arms that it deems  to be sub-optimal.} variant of UCB1 that 
has a gap-dependent regret bound of $O\left(\frac{K\log T\Delta^{2}}{\Delta}\right)$, which is better than that of UCB1. On the other hand, the worst case gap-independent regret bound of UCB-Improved is $O\left(\sqrt{KT\log K}\right)$. Recently in \citet{lattimore2015optimally}, the authors showed that  the algorithm OCUCB achieves order-optimal gap-dependent regret bound of $O\left(\sum_{i=2}^{K}\frac{\log\left(T/H_i\right)}{\Delta_i}\right)$ where $H_i=\sum_{j=1}^{K}\min\lbrace \frac{1}{\Delta_i^2},\frac{1}{\Delta_j^2}\rbrace$ and gap-independent regret bound of $O\left( \sqrt{KT}\right)$. But OCUCB does not take into account the variance of the arms and we show that our algorithm outperforms OCUCB in all the environments considered. 

	We must also mention about UCBV \citep{audibert2009exploration} algorithm which is quite different  from the above algorithms owing to its utilization of variance estimates. UCBV has a gap-dependent regret bound of $O\left(\frac{K\sigma_{\max}^{2}\log T}{\Delta}\right)$, where $\sigma_{\max}^{2}$ denotes the maximum variance among all the arms $i\in \A$. Its gap-independent regret bound can be inferred to be same as that of UCB1 i.e $O \left(\sqrt{KT\log T}\right)$. Empirically, \citet{audibert2009exploration} showed that UCBV outperforms UCB1 in several scenarios. 