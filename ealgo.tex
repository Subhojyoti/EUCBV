%%%%%%%%%%%%%%%% alg-custom-block %%%%%%%%%%%%
\algblock{ArmElim}{EndArmElim}
\algnewcommand\algorithmicArmElim{\textbf{\em Arm Elimination}}
 \algnewcommand\algorithmicendArmElim{}
\algrenewtext{ArmElim}[1]{\algorithmicArmElim\ #1}
\algrenewtext{EndArmElim}{\algorithmicendArmElim}

\algblock{ResParam}{EndResParam}
\algnewcommand\algorithmicResParam{\textbf{\em Reset Parameters}}
 \algnewcommand\algorithmicendResParam{}
\algrenewtext{ResParam}[1]{\algorithmicResParam\ #1}
\algrenewtext{EndResParam}{\algorithmicendResParam}

\begin{algorithm}[!h]
\caption{EUCBV}
\label{alg:eucbv}
\begin{algorithmic}
\State {\bf Input:} Time horizon $T$, exploration parameters $\rho$ and $\psi$.
\State {\bf Initialization:} Set $m:=0$, $B_{0}:=A$, $\epsilon_{0}:=1$, $M=\big \lfloor \frac{1}{2}\log_{2} \frac{T}{e}\big\rfloor$, $n_{0}=\bigg\lceil\frac{\log{(\psi T\epsilon_{0}^{2})}}{2\epsilon_{0}}\bigg\rceil$ and  $N_{0}=Kn_{0}$.
\State Pull each arm once
\For{$t=K+1,..,T$}	
\State Pull arm $i\in \argmax_{j\in B_{m}}\bigg\lbrace \hat{r}_{j} + \sqrt{\frac{\rho\hat{v}_{j}\log{(\psi T\epsilon_{m}^{2})}}{4 z_{j}}+ \frac{\rho\log{(\psi T\epsilon_{m})}}{4 z_{j}}} \bigg\rbrace$, where $z_j$ is the number of times arm $j$ has been pulled
\State $t:=t+1$
\ArmElim
\State For each arm $i \in B_{m}$, remove arm $i$ from $B_{m}$ if,
\begin{align*}
& \hat{r}_{i} + \sqrt{\frac{\rho\hat{v}_{i}\log{(\psi T\epsilon_{m})}}{4 z_{i}} + \frac{\rho\log{(\psi T\epsilon_{m})}}{4 z_{i}}} < \max_{{j}\in B_{m}}\bigg\lbrace\hat{r}_{j} -\sqrt{\frac{\rho\hat{v}_{j}\log{(\psi T\epsilon_{m})}}{4 z_{j}} + \frac{\rho\log{(\psi T\epsilon_{m})}}{4 z_{j}}} \bigg\rbrace
\end{align*}
%\State $|B_{m}|:=|B_{m}|-1$
\EndArmElim

\If{$t\geq N_{m}$ and $m\leq M$}
\ResParam
\State $\epsilon_{m+1}:=\frac{\epsilon_{m}}{2}$\vspace{0.5ex}
\State $B_{m+1}:=B_{m}$
\State $n_{m+1}:=\bigg\lceil\frac{\log{(\psi T\epsilon_{m+1}^{2})}}{2\epsilon_{m+1}}\bigg\rceil$
\State $N_{m+1}:=t+|B_{m+1}| n_{m+1}$
\State $m:=m+1$
\EndResParam
\State Stop if $|B_{m}|=1$ and pull ${i}\in B_{m}$ till $T$ is reached.
\EndIf
\EndFor
\end{algorithmic}
%\vspace*{-0.42em}
\end{algorithm}
%\vspace*{-0.42em}
\textbf{2.1 Notations:} We denote the set of arms by $\A$, with the individual arms labeled $i, i=1,\ldots,K$. We denote an arbitrary round of EUCBV by $m$. For simplicity, we assume that the optimal arm is unique and denote it by ${*}$. We denote the sample mean of the rewards for an arm $i$ at time instant $t$ by $\hat{r}_{i}(t)=\frac{1}{z_{i}(t)}\sum_{\ell=1}^{z_i(t)} X_{i,\ell}$, where $X_{i,\ell}$ is the reward sample received when arm $i$ is pulled for the $z$-th time. $z_i(t)$ is the number of times an arm $i$ has been pulled till timestep $t$. We denote the true variance of an arm by $\sigma_i^{2}$ while $\hat{v}_{i}(t)$ is the estimated variance, i.e., $\hat{v}_{i}(t)=\frac{1}{z_i(t)}\sum_{\ell=1}^{z_{i}(t)}(X_{i,\ell}-\hat{r}_{i})^{2}$. Whenever there is no ambiguity about the underlaying  time index $t$, for simplicity we neglect $t$ from the notations and simply use  $\hat{r}_i, \hat{v}_i,$ and $z_i$ to denote the respective quantities. We assume the rewards of all arms are bounded in $[0,1]$.

\textbf{2.2 The algorithm:} Earlier arm elimination algorithms like Median Elimination \cite{even2006action} and UCB-Improved \cite{auer2010ucb} mainly suffered from two basic problems: \\
\begin{inparaenum}[\bfseries(i)]
\item \textit{Initial exploration:} Both of these algorithms pull each arm equal number of times in each round, and hence waste a significant number of pulls in initial explorations. \\
\item \textit{Conservative arm-elimination:} In UCB-Improved, arms are eliminated conservatively, i.e, only after $\epsilon_{m}<\frac{\Delta_{i}}{2}$, the sub-optimal arm $i$ is discarded with high probability. In the worst case scenario when $K$ is large and the gaps are uniform  ($r_{1}=r_{2}=\cdots=r_{K-1}<r^{*}$) and small this results in very high regret.\\
\end{inparaenum}
%For any round $m$ UCB-Improved pulls all arms $n_{m}=\left\lceil \frac{ 2\log(T\epsilon_{m})}{\epsilon_{m}} \right\rceil$ number of times. The quantity $\epsilon_{m}$ is initialized to $1$ and halved after every round.
UCBEV algorithm which is mainly based on the arm elimination technique of the UCB-Improved algorithm remedies these by employing exploration regulatory factor $\psi$ and arm elimination parameter $\rho$ for aggressive elimination of sub-optimal arms. Along with these, like CCB \cite{liu2016modification} algorithm, EUCBV uses optimistic greedy sampling whereby at every timestep it only pulls the arm with the highest upper confidence bound rather than pulling all the arms equal number of times in each round. Also, unlike the UCB-Improved, UCB1. MOSS and OCUCB algorithm (which are based on mean estimation) EUCBV employs variance estimates (as in \citet{audibert2009exploration}) for arm elimination. Further, we allow for arm-elimination at every time-step, which is in contrast to the earlier work (e.g., \cite{auer2010ucb}; \cite{even2006action}) where the arm elimination takes place only at the end of the respective exploration rounds. 




%In \cite{liu2016modification} the authors identified two major problems with UCB-Improved: 	\\
%\begin{inparaenum}[\bfseries(i)]
%\item Early exploration: Since UCB-Improved pulls each arm equal number of times in each round, a significant number of pulls is wasted in initial explorations. For any round $m$ UCB-Improved pulls all arms $n_{m}=\left\lceil \frac{ 2\log(T\epsilon_{m})}{\epsilon_{m}} \right\rceil$ number of times. The quantity $\epsilon_{m}$ is initialized to $1$ and halved after every round.\\
%\item Conservative arm-elimination: In UCB-Improved, arms are eliminated conservatively, i.e, only after $\epsilon_{m}<\frac{\Delta_{i}}{2}$, the sub-optimal arm $i$ is discarded with high probability. In the worst case scenario when $K$ is large and the gaps are identical ($r_{1}=r_{2}=\cdots=r_{K-1}<r^{*}$) and small this is very disadvantageous.\\
%\end{inparaenum}
%To reduce early exploration, the number of pulls $n_m$ allocated to each arm per round in EUCBV is lower than that of UCB-Improved and also that of Median-Elimination, which used $n_m=\frac{4}{\epsilon}\log\big(\frac{3}{\delta}\big)$, where $\epsilon,\delta$ are confidence parameters. As described in the pseudocode in Algorithm~\ref{alg:eucbv}, each timestep of EUCBV involves both individual arm as well as cluster elimination conditions. In EUCBV we also introduce the idea of optimistic greedy sampling similar to \citet{liu2016modification} which they used to modify the UCB-Improved algorithm. In optimistic greedy sampling, we only sample the arm with the highest upper confidence bound in each timestep. EUCBV update parameters when a round is complete. It divides each round into $|B_{m}|n_{m}$ timesteps so that each surviving arms can be allocated atmost $n_{m}$ pulls. The exploration regulatory factor $\psi$ governing the arm and cluster elimination conditions in EUCBV is more aggressive than that in UCB-Improved. With appropriate choices of $\psi$ and $\rho$, we can achieve aggressive elimination even when the gaps $\Delta_i$ are small and $K$ is large. \\
%
%In \citet{liu2016modification}, the authors also recommend incorporating an exploration regulatory factor $d_i$ inside the log-term of the UCB values, i.e., $\max \lbrace\hat{r}_{i}+\sqrt{\frac{d_{i}\log T{\epsilon}_{m}}{2n_{m}}}\rbrace$. The authors choices for $d_i$ include $\frac{T}{z_{i}}$, $\frac{\sqrt{T}}{z_{i}}$ and $\frac{\log T}{z_{i}}$, where $z_{i}$ is the number of times an arm ${i}$ has been pulled. Unlike \citet{liu2016modification}, we employ a different exploration regulatory factor $\psi=\dfrac{T}{K^2}$ and we derive a cumulative regret bound as opposed to the simple regret bound derived in \citet{liu2016modification}.

	

