\begin{thebibliography}{}

\bibitem[Audibert and Bubeck, 2009]{audibert2009minimax}
Audibert, J.-Y. and Bubeck, S. (2009).
\newblock Minimax policies for adversarial and stochastic bandits.
\newblock In {\em COLT}, pages 217--226.

\bibitem[Auer and Ortner, 2010]{auer2010ucb}
Auer, P. and Ortner, R. (2010).
\newblock Ucb revisited: Improved regret bounds for the stochastic multi-armed
  bandit problem.
\newblock {\em Periodica Mathematica Hungarica}, 61(1-2):55--65.

\bibitem[Kaufmann et~al., 2012]{kaufmann2012bayesian}
Kaufmann, E., Capp{\'e}, O., and Garivier, A. (2012).
\newblock On bayesian upper confidence bounds for bandit problems.
\newblock In {\em AISTATS}, pages 592--600.

\bibitem[Lattimore, 2015]{lattimore2015optimally}
Lattimore, T. (2015).
\newblock Optimally confident ucb: Improved regret for finite-armed bandits.
\newblock {\em arXiv preprint arXiv:1507.07880}.

\bibitem[Liu and Tsuruoka, 2016]{liu2016modification}
Liu, Y.-C. and Tsuruoka, Y. (2016).
\newblock Modification of improved upper confidence bounds for regulating
  exploration in monte-carlo tree search.
\newblock {\em Theoretical Computer Science}.

\end{thebibliography}
