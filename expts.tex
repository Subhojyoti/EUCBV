In this section we conduct extensive empirical evaluations of EUCBV against several other popular bandit algorithms.  We use cumulative regret as the metric of comparison. We implement the following algorithms:  KL-UCB \cite{garivier2011kl}, DMED \cite{honda2010asymptotically}, MOSS \cite{audibert2009minimax}, UCB1 \cite{auer2002finite}, UCB-Improved \cite{auer2010ucb}, Median Elimination \cite{even2006action}, Thompson Sampling (TS) \cite{agrawal2011analysis}, OCUCB \cite{lattimore2015optimally}, Bayes-UCB (BU) \cite{kaufmann2012bayesian} and UCB-V \cite{audibert2009exploration}\footnote{The implementation for KL-UCB, Bayes-UCB and DMED were taken from \cite{CapGarKau12}}. The parameters of EUCBV algorithm for all the experiments are set as follows: $\psi=\frac{T}{K^2}$ and $\rho =0.5$ (as in Corollary \ref{Result:Corollary:1}).

\begin{figure}[!h]
    \centering
    \begin{tabular}{cc}
    \setlength{\tabcolsep}{0.1pt}
    \subfigure[0.25\textwidth][Expt-$1$: $20$ Bernoulli-distributed arms ]
    %with $r_{i_{{i}\neq {*}}}=0.07$ and $r^{*}=0.1$
    {
    		\pgfplotsset{
		tick label style={font=\Large},
		label style={font=\Large},
		legend style={font=\Large},
		ylabel style={yshift=32pt},
		%legend style={legendshift=32pt},
		}
        \begin{tikzpicture}[scale=0.55]
      	\begin{axis}[
		xlabel={timestep},
		ylabel={Cumulative Regret},
		grid=major,
        %clip mode=individual,grid,grid style={gray!30},
        clip=true,
        %clip mode=individual,grid,grid style={gray!30},
  		legend style={at={(0.5,1.5)},anchor=north, legend columns=3} ]
      	% UCB
		\addplot table{results/NewExpt/Expt1/UCBV01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt11/NEUCBV011_comp_subsampled.txt};
		%\addplot table{results/NewExpt/Expt1/NEUCBV01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt1/KLUCB01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt1/MOSS01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt1/DMED01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt1/UCB01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt1/TS01_comp_subsampled.txt};
		%\addplot table{results/NewExpt/Expt11/TS01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt1/OCUCB01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt1/BU01_comp_subsampled.txt};
      	\legend{UCB-V,EUCBV,KL-UCB,MOSS,DMED,UCB1,TS,OCUCB,BU}      	
      	\end{axis}
      	\end{tikzpicture}
  		\label{fig:1}
    }
    &
    \subfigure[0.25\textwidth][Expt-$2$: $100$ Gaussian-distributed arms ]
    %with $r_{i_{{i}\neq {*}:1-33}}=0.1$, $r_{i_{{i}\neq {*}:34-99}}=0.6$, $r^{*}_{i=100}=0.9$ and $\sigma_{i=1:100}^{2} = 0.3$
    {
    		\pgfplotsset{
		tick label style={font=\Large},
		label style={font=\Large},
		legend style={font=\Large},
		ylabel style={yshift=32pt},
		}
        \begin{tikzpicture}[scale=0.55]
        \begin{axis}[
		xlabel={timestep},
		ylabel={Cumulative Regret},
        %clip mode=individual,grid,grid style={gray!30},
       	grid=major,
       	clip=true,
  		legend style={at={(0.5,1.5)},anchor=north, legend columns=3} ]
      	% UCB
        \addplot table{results/NewExpt/Expt2/UCB01_comp_subsampled.txt};
		%\addplot table{results/NewExpt/Expt2_2/clUCB01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt2/NEUCBV01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt2/MOSS01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt2/OCUCB01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt2/TS01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt2/KLUCB01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt2/BU01_comp_subsampled.txt};
		%\addplot table{results/NewExpt/Expt2/MedElim01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt2/UCBR01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt2/UCBV01_comp_subsampled.txt};
		
		%\legend{UCB1,EUCBV,MOSS,OCUCB,Med-Elim,UCB-Imp,UCBV}
		\legend{UCB1,EUCBV,MOSS,OCUCB,TS,KLUCB-Gauss,BU,UCB-Imp,UCBV}
		%\legend{UCB1,EUCBV,MOSS,OCUCB,TS,KLUCB-Gauss,BU}
      	\end{axis}
      	\end{tikzpicture}
   		\label{fig:2}
    }
    \end{tabular}
    \caption{Cumulative regret for various bandit algorithms on two stochastic K-armed bandit environments. }
    \label{fig:karmed}
    \vspace*{-1em}
\end{figure}
% For the purpose of performance comparison


\textbf{Experiment-1 (Bernoulli with uniform gaps):} This experiment is conducted to observe the performance of EUCBV over a short horizon. The horizon $T$ is set to $60000$. These type of cases are frequently encountered in web-advertising domain. The testbed comprises of $20$ Bernoulli distributed arms with expected rewards of the arms as $r_{i_{{i}\neq {*}}}=0.07$ and $r^{*}=0.1$. The regret is averaged over $100$ independent runs and is shown in Figure \ref{fig:1}. EUCBV, MOSS, UCB1, UCB-V, KL-UCB, TS, BU and DMED are run in this experimental setup. Here not only do we observe that EUCBV performs better than all the non-variance based  algorithms like MOSS, OCUCB, UCB-Improved and UCB1, but it also outperforms UCBV because of the choice of the exploration parameters. Because of the small gaps and short horizon $T$, we do not implement UCB-Improved and Median Elimination on this test-case. EUCBV is only slightly better than TS in this setting but better than other algorithms like Bayes-UCB and KL-UCB.

\textbf{Experiment-2 (Failure of TS):} This experiment is conducted on a large horizon and over a large set of arms. The horizon $T$ is set for a large duration of $3\times 10^{5}$. This testbed comprises of $100$ arms involving Gaussian reward distributions with expected rewards of the arms $r_{1:33}=0.7$, $r_{34:99}=0.8$ and $r^{*}_{100}=0.9$ with variance set as $\sigma_{1:33}^{2} = 0.7,\sigma_{34:99}^{2} = 0.1$ and $r^{*}_{100}=0.7$. The regret is averaged over $100$ independent runs and is shown in Figure \ref{fig:2}. From the results in Figure \ref{fig:2}, we observe that since the gaps are small and the variances of the optimal arm and the arms farthest from the optimal arm are the highest, EUCBV outperforms all the non-variance based algorithms MOSS, OCUCB, UCB1, TS, UCB-Improved and Median-Elimination($\epsilon=0.1,\delta=0.1$). The performance of Median elimination is extremely weak in comparison with the other algorithms and its plot is not shown in Figure \ref{fig:2}. We omit its plot in order to more clearly show the difference between EUCBV, MOSS and OCUCB. Also note that the order of magnitude in the y-axis (cumulative regret) is $10^4$. The performance of TS is also weak and this is in line with the observation in  \cite{lattimore2015optimally} that the worst case regret of TS when Gaussian prior is used is $\Omega\left( \sqrt{KT\log T}\right)$. Again both Bayes-UCB and KL-UCB-Gauss perform much worse than TS. 
%Also the performance of UCB-Improved is poor in comparison to other algorithms, which is probably because of pulls wasted in initial exploration whereas EUCBV with the choice of $\psi$ and $\rho$ performs much better.

\begin{figure}[!h]
    \centering
    \begin{tabular}{cc}
    \subfigure[0.25\textwidth][Expt-$3$: $20$ to $100$ Gaussian-distributed arms]
    %with $r_{i_{{i}\neq {*}}}=0.05$ and $r^{*}=0.1$
    {
    	\pgfplotsset{
		tick label style={font=\Large},
		label style={font=\Large},
		legend style={font=\Large},
		ylabel style={yshift=32pt},
		}
        \begin{tikzpicture}[scale=0.55]
        \begin{axis}[
		xlabel={Arms},
		ylabel={Cumulative Regret},
        %clip mode=individual,grid,grid style={gray!30},
		grid=major,
		clip=true,
  		legend style={at={(0.5,1.3)},anchor=north, legend columns=3} ]
        % UCB
		\addplot table{results/NewExpt/Expt31/plotFinalMOSS20_100.txt};
		\addplot table{results/NewExpt/Expt31/plotFinalNEUCBV20_100.txt};
		\addplot table{results/NewExpt/Expt31/plotFinalOCUCB20_100.txt};
		\addplot table{results/NewExpt/Expt31/plotFinalTS20_100.txt};
      	\legend{MOSS,EUCBV,OCUCB,TS}
      	\end{axis}
        \end{tikzpicture}
        \label{fig:3}
    }
    &
    \subfigure[0.25\textwidth][Expt-$4$: Advanced Setting]
    %: $r_{1:33}=0.4$, $r_{34:99}=0.6$, $r^{*}_{100}=0.9$; $\sigma_{1:33}^{2}=0.2$, $\sigma_{34:99}^{2}=0.1$,  $\sigma_{100}^{2}=0.4$
    {
    		\pgfplotsset{
		tick label style={font=\Large},
		label style={font=\Large},
		legend style={font=\Large},
		ylabel style={yshift=32pt},
		}
        \begin{tikzpicture}[scale=0.55]
      	\begin{axis}[
		ylabel={Cumulative Regret},
		xlabel={timestep},
		grid=major,
        %clip mode=individual,grid,grid style={gray!30},
        clip=true,
        %clip mode=individual,grid,grid style={gray!30},
  		legend style={at={(0.5,1.3)},anchor=north, legend columns=3} ]
      	% UCB
		%\addplot table{results/NewExpt/Expt4/UCBV01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt41/MOSS01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt41/NEUCBV01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt41/OCUCB01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt41/TS01_comp_subsampled.txt};
		%\addplot table{results/NewExpt/Expt4/KLUCB01_comp_subsampled.txt};
		%\addplot table{results/NewExpt/Expt4/BU01_comp_subsampled.txt};
      	%\legend{MOSS,EUCBV,OCUCB,TS,KLUCB,BU} 
      	\legend{MOSS,EUCBV,OCUCB,TS} 
      	\end{axis}
      	\end{tikzpicture}
  		\label{fig:4}
    }
	\end{tabular}
	\label{fig:furtherExpt1}
    \caption{Further Experiments with EUCBV}
    \vspace*{-1em}
\end{figure}
%\vspace*{-0.5em}
\textbf{Experiment-3 (Gaussian with large horizon and uniform gaps):} This experiment is conducted to show the stability and performance of EUCBV over a very large horizon and over a large number of arms. This testbed comprises of $20-100$ (interval of $10$) arms with Gaussian reward distributions, where the expected rewards of the arms are $r_{i_{{i}\neq {*}}}=0.05$ and $r^{*}=0.1$ and variances are set as $\sigma_{i:i\neq *}^{2}=0.25$ and $\sigma_{*}^{2}=0.7$. For each of these testbeds of $20-100$ arms, we report the cumulative regret averaged over $100$ independent runs. The horizon is set at $T=10^{5} + K_{20:100}^{3}$ timesteps. We report the performance of MOSS, TS, OCUCB and EUCBV only over this uniform gap setup. From the results in Figure \ref{fig:3}, it is evident that the growth of regret for EUCBV  is much lower than that of TS, OCUCB and MOSS. Bayes-UCB and KLUCB are not feasible to be run over such a large horizon as these algorithms are extremely slow in their execution.

%Please note that algorithms like Thompson Sampling or Bayes-UCB are too slow to be run for such large arms (see \citet{lattimore2015optimally}) and  over such large horizon.
%This also corroborates the finding of \citet{lattimore2015optimally} which states that MOSS breaks down only when the number of arms are exceptionally large or the horizon is unreasonably high and gaps are very small. We consistently see that in uniform gap testcases EUCBV outperforms OCUCB.

\textbf{Experiment-4 (Advance Setting):} This experiment is conducted on $100$ Gaussian distributed arms such that expected rewards of the arms $r_{1:33}=0.4$, $r_{34:99}=0.6$, $r^{*}_{100}=0.9$ and the variance is set as $\sigma_{1:33}^{2}=0.2$, $\sigma_{34:99}^{2}=0.1$,  $\sigma_{100}^{2}=0.7$ and $T=3\times 10^5$. This experiment is conducted to show that in certain environments, when the variance of the optimal arm is higher than all the other sub-optimal arms, then EUCBV performs exceptionally well. We refer to this setup as Advanced Setting because here the chosen variance values are such that only variance-aware algorithms will perform well because the variance of the optimal arm is chosen to be higher than the other arms and so algorithms that are not variance-aware will spent a significant amount of pulls trying to find the optimal arm. The result is shown in Figure \ref{fig:4}. Predictably EUCBV, which allocates pulls proportional to the variance of the arms, outperforms TS, MOSS and OCUCB. The plot for UCBV, KL-UCB-Gauss and Bayes-UCB are omitted from the figure and they perform very poorly compared to other algorithms. We omit their plots to clearly show how EUCBV outperforms its nearest competitors TS, MOSS and OCUCB. Note that EUCBV by virtue of its aggressive exploration parameters outperforms UCBV in all the experiments even though UCBV is a variance based algorithm. Also in all the experiments with Gaussian distributions EUCBV significantly outperforms all the Bayesian algorithms.



