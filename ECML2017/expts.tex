In this section, we conduct extensive empirical evaluations of EUCBV against several other popular bandit algorithms. We use expected cumulative regret as the metric of comparison. We compare with the following algorithms:  KL-UCB+ \cite{garivier2011kl}, DMED \cite{honda2010asymptotically}, MOSS \cite{audibert2009minimax}, UCB1 \cite{auer2002finite}, UCB-Improved \cite{auer2010ucb}, Median Elimination \cite{even2006action}, Thompson Sampling (TS) \cite{agrawal2011analysis}, OCUCB \cite{lattimore2015optimally}, Bayes-UCB (BU) \cite{kaufmann2012bayesian} and UCB-V \cite{audibert2009exploration}\footnote{The implementation for KL-UCB, Bayes-UCB and DMED were taken from \cite{CapGarKau12}}. The parameters of EUCBV algorithm for all the experiments are set as follows: $\psi=\frac{T}{K^2}$ and $\rho =0.5$ (as in Corollary \ref{Result:Corollary:1}). Please note that KL-UCB+ empirically outperforms KL-UCB (as shown in \cite{garivier2011kl}).

\begin{figure}[!h]
    \centering
    \begin{tabular}{cc}
    \setlength{\tabcolsep}{0.1pt}
    \subfigure[0.25\textwidth][Expt-$1$: $20$ Bernoulli-distributed arms ]
    %with $r_{i_{{i}\neq {*}}}=0.07$ and $r^{*}=0.1$
    {
    		\pgfplotsset{
		tick label style={font=\Large},
		label style={font=\Large},
		legend style={font=\Large},
		ylabel style={yshift=5pt},
		%legend style={legendshift=32pt},
		}
        \begin{tikzpicture}[scale=0.6]
      	\begin{axis}[
		xlabel={timestep},
		ylabel={Cumulative Regret},
		grid=major,
        %clip mode=individual,grid,grid style={gray!30},
        clip=true,
        %clip mode=individual,grid,grid style={gray!30},
  		legend style={at={(0.5,1.5)},anchor=north, legend columns=3} ]
      	% UCB
		\addplot table{results/NewExpt/Expt1/UCBV01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt11/NEUCBV011_comp_subsampled.txt};
		%\addplot table{results/NewExpt/Expt1/NEUCBV01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt1/KLUCB01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt1/MOSS01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt1/DMED01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt1/UCB01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt1/TS01_comp_subsampled.txt};
		%\addplot table{results/NewExpt/Expt11/TS01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt1/OCUCB01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt1/BU01_comp_subsampled.txt};
      	\legend{UCB-V,EUCBV,KL-UCB+,MOSS,DMED,UCB1,TS,OCUCB,BU}      	
      	\end{axis}
      	\end{tikzpicture}
  		\label{fig:1}
    }
    &
    \subfigure[0.25\textwidth][Expt-$2$: $100$ Gaussian-distributed arms ]
    %with $r_{i_{{i}\neq {*}:1-33}}=0.1$, $r_{i_{{i}\neq {*}:34-99}}=0.6$, $r^{*}_{i=100}=0.9$ and $\sigma_{i=1:100}^{2} = 0.3$
    {
    		\pgfplotsset{
		tick label style={font=\Large},
		label style={font=\Large},
		legend style={font=\Large},
		ylabel style={yshift=5pt},
		}
        \begin{tikzpicture}[scale=0.6]
        \begin{axis}[
		xlabel={timestep},
		ylabel={Cumulative Regret},
        %clip mode=individual,grid,grid style={gray!30},
       	grid=major,
       	clip=true,
  		legend style={at={(0.5,1.5)},anchor=north, legend columns=3} ]
      	% UCB
		\addplot table{results/NewExpt/Expt2/UCBV01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt2/NEUCBV01_comp_subsampled.txt};
		%\addplot table{results/NewExpt/Expt1/NEUCBV01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt2/KLUCB01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt2/MOSS01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt2/UCBR01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt2/UCB01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt2/TS01_comp_subsampled.txt};
		%\addplot table{results/NewExpt/Expt11/TS01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt2/OCUCB01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt2/BU01_comp_subsampled.txt};      	
      	\legend{UCB-V,EUCBV,KL-UCB-Gauss+,MOSS,UCB-Imp,UCB1,TS,OCUCB,BU}
%      	
%      	
%        \addplot table{results/NewExpt/Expt2/UCB01_comp_subsampled.txt};
%		%\addplot table{results/NewExpt/Expt2_2/clUCB01_comp_subsampled.txt};
%		\addplot table{results/NewExpt/Expt2/NEUCBV01_comp_subsampled.txt};
%		\addplot table{results/NewExpt/Expt2/MOSS01_comp_subsampled.txt};
%		\addplot table{results/NewExpt/Expt2/OCUCB01_comp_subsampled.txt};
%		\addplot table{results/NewExpt/Expt2/TS01_comp_subsampled.txt};
%		\addplot table{results/NewExpt/Expt2/KLUCB01_comp_subsampled.txt};
%		\addplot table{results/NewExpt/Expt2/BU01_comp_subsampled.txt};
%		%\addplot table{results/NewExpt/Expt2/MedElim01_comp_subsampled.txt};
%		\addplot table{results/NewExpt/Expt2/UCBR01_comp_subsampled.txt};
%		\addplot table{results/NewExpt/Expt2/UCBV01_comp_subsampled.txt};
%		%\legend{UCB1,EUCBV,MOSS,OCUCB,Med-Elim,UCB-Imp,UCBV}
%		\legend{UCB1,EUCBV,MOSS,OCUCB,TS,KL-UCB-Gauss,BU,UCB-Imp,UCBV}
%		%\legend{UCB1,EUCBV,MOSS,OCUCB,TS,KLUCB-Gauss,BU}
      	\end{axis}
      	\end{tikzpicture}
   		\label{fig:2}
    }
    \end{tabular}
    \caption{A comparison of the cumulative regret incurred by the various bandit algorithms. }
    \label{fig:karmed}
    \vspace*{-1em}
\end{figure}
% For the purpose of performance comparison


\textbf{Experiment-1 (Bernoulli with uniform gaps):} This experiment is conducted to observe the performance of EUCBV over a short horizon. The horizon $T$ is set to $60000$. The testbed comprises of $20$ Bernoulli distributed arms with expected rewards of the arms as $r_{1:19}=0.07$ and $r^{*}_{20}=0.1$ and these type of cases are frequently encountered in web-advertising domain (see \cite{garivier2011kl}). The regret is averaged over $100$ independent runs and is shown in Figure \ref{fig:1}. EUCBV, MOSS, OCUCB, UCB1, UCB-V, KL-UCB+, TS, BU and DMED are run in this experimental setup. Not only do we observe that EUCBV performs better than all the non-variance based algorithms such as MOSS, OCUCB, UCB-Improved and UCB1, but it also outperforms UCBV because of the choice of the exploration parameters. Because of the small gaps and short horizon $T$, we do not compare with UCB-Improved and Median Elimination for this test-case. EUCBV is only marginally better than TS, KL-UCB+, Bayes-UCB in this setting but substantially better than all the other algorithms.

\textbf{Experiment-2 (Failure of TS):} This experiment is conducted to demonstrate that in certain environments when the horizon is large, gaps are small and the variance of the optimal arm is high, the Bayesian algorithms (like TS) do not perform well. This setting comprises of a large horizon of $T = 3\times 10^{5}$ timesteps and a large set of arms. This testbed comprises of $100$ arms involving Gaussian reward distributions with expected rewards of the arms $r_{1:33}=0.7$, $r_{34:99}=0.8$ and $r^{*}_{100}=0.9$ with variance set as $\sigma_{1:33}^{2} = 0.7,\sigma_{34:99}^{2} = 0.1$ and $\sigma^{2}_{100}=0.7$. The regret is averaged over $100$ independent runs and is shown in Figure \ref{fig:2}. From the results in Figure \ref{fig:2}, we observe that since the gaps are small and the variances of the optimal arm and the arms farthest from the optimal arm are the highest, EUCBV, which allocates pulls proportional to the variances of the arms,  outperforms all the non-variance based algorithms MOSS, OCUCB, UCB1, TS, UCB-Improved and Median-Elimination ($\epsilon=0.1,\delta=0.1$). The performance of Median-Elimination is extremely weak in comparison with the other algorithms and its plot is not shown in Figure \ref{fig:2}. We omit its plot in order to more clearly show the difference between EUCBV, MOSS and OCUCB. Also note that the order of magnitude in the y-axis (cumulative regret) of Figure \ref{fig:2} is $10^4$. The performance of TS is also weak and this is in line with the observation in  \cite{lattimore2015optimally} that the worst case regret of TS when Gaussian prior is used is $\Omega\left( \sqrt{KT\log T}\right)$. Again both Bayes-UCB and KL-UCB-Gauss+ perform much worse than TS. The performance of DMED is similar to KL-UCB-Gauss+ in this setup and its plot is omitted. 
%Also the performance of UCB-Improved is poor in comparison to other algorithms, which is probably because of pulls wasted in initial exploration whereas EUCBV with the choice of $\psi$ and $\rho$ performs much better.

\begin{figure}[!h]
    \centering
    \begin{tabular}{cc}
    \subfigure[0.25\textwidth][Expt-$3$: Advanced Setting]
    {
    		\pgfplotsset{
		tick label style={font=\Large},
		label style={font=\Large},
		legend style={font=\Large},
		ylabel style={yshift=5pt},
		}
        \begin{tikzpicture}[scale=0.6]
      	\begin{axis}[
		ylabel={Cumulative Regret},
		xlabel={timestep},
		grid=major,
        %clip mode=individual,grid,grid style={gray!30},
        clip=true,
        %clip mode=individual,grid,grid style={gray!30},
  		legend style={at={(0.5,1.3)},anchor=north, legend columns=3} ]
      	% UCB
		%\addplot table{results/NewExpt/Expt4/UCBV01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt41/MOSS01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt41/NEUCBV01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt41/OCUCB01_comp_subsampled.txt};
		\addplot table{results/NewExpt/Expt41/TS01_comp_subsampled.txt};
		%\addplot table{results/NewExpt/Expt41/KLUCB01_comp_subsampled.txt};
		%\addplot table{results/NewExpt/Expt4/BU01_comp_subsampled.txt};
      	%\legend{MOSS,EUCBV,OCUCB,TS,KLUCB,BU} 
      	\legend{MOSS,EUCBV,OCUCB,TS} 
      	\end{axis}
      	\end{tikzpicture}
  		\label{fig:4}
    }
    &
    \subfigure[0.25\textwidth][Expt-$4$: $20$ to $100$ Gaussian-distributed arms]
    %with $r_{i_{{i}\neq {*}}}=0.05$ and $r^{*}=0.1$
    {
    	\pgfplotsset{
		tick label style={font=\Large},
		label style={font=\Large},
		legend style={font=\Large},
		ylabel style={yshift=5pt},
		}
        \begin{tikzpicture}[scale=0.6]
        \begin{axis}[
		xlabel={Arms},
		ylabel={Cumulative Regret},
        %clip mode=individual,grid,grid style={gray!30},
		grid=major,
		clip=true,
  		legend style={at={(0.5,1.3)},anchor=north, legend columns=3} ]
        % UCB
		\addplot table{results/NewExpt/Expt31/plotFinalMOSS20_100.txt};
		\addplot table{results/NewExpt/Expt31/plotFinalNEUCBV20_100.txt};
		\addplot table{results/NewExpt/Expt31/plotFinalOCUCB20_100.txt};
		\addplot table{results/NewExpt/Expt31/plotFinalTS20_100.txt};
      	\legend{MOSS,EUCBV,OCUCB,TS}
      	\end{axis}
        \end{tikzpicture}
        \label{fig:3}
    }
    %: $r_{1:33}=0.4$, $r_{34:99}=0.6$, $r^{*}_{100}=0.9$; $\sigma_{1:33}^{2}=0.2$, $\sigma_{34:99}^{2}=0.1$,  $\sigma_{100}^{2}=0.4$
	\end{tabular}
	\label{fig:furtherExpt1}
    \caption{Further Experiments with EUCBV}
    \vspace*{-1em}
\end{figure}
%\vspace*{-0.5em}


%Because of the poor performance of Bayes-UCB and KL-UCB in the last two experiments we do not implement them in this setup.
%Please note that algorithms like Thompson Sampling or Bayes-UCB are too slow to be run for such large arms (see \citet{lattimore2015optimally}) and  over such large horizon.
%This also corroborates the finding of \citet{lattimore2015optimally} which states that MOSS breaks down only when the number of arms are exceptionally large or the horizon is unreasonably high and gaps are very small. We consistently see that in uniform gap testcases EUCBV outperforms OCUCB.

\textbf{Experiment-3 (Advanced Setting):} This experiment demonstrates that in certain environments, when the variance of the optimal arm is higher than all the other sub-optimal arms, EUCBV performs exceptionally well. This experiment is conducted on $100$ Gaussian distributed arms such that expected rewards of the arms are $r_{1:33}=0.4$, $r_{34:99}=0.6$, $r^{*}_{100}=0.9$ and the variance is set as $\sigma_{1:33}^{2}=0.2$, $\sigma_{34:99}^{2}=0.1$,  $\sigma_{100}^{2}=0.7$ and $T=3\times 10^5$. We refer to this setup as Advanced Setting because here the chosen variance values are such that only variance-aware algorithms will perform very well because the variance of the optimal arm is chosen to be higher than all the other arms. The algorithms that are not variance-aware will spend a significant amount of pulls trying to find the optimal arm. The result is shown in Figure \ref{fig:4}. Predictably EUCBV, which allocates pulls proportional to the variance of the arms, outperforms its closest competitors TS, MOSS and OCUCB. The plot for UCBV, KL-UCB-Gauss+ and Bayes-UCB are omitted from the figure and their performance is extremely weak in comparison with other algorithms. We omit their plots to clearly show how EUCBV outperforms its nearest competitors TS, MOSS and OCUCB. Note that EUCBV by virtue of its aggressive exploration parameters outperforms UCBV in all the experiments even though UCBV is a variance-based algorithm.

\textbf{Experiment-4 (Gaussian with large horizon and uniform gaps):} This experiment is conducted to show the stability and performance of EUCBV over a very large horizon and over a large number of arms. This testbed comprises of $20-100$ (interval of $10$) arms with Gaussian reward distributions, where the expected rewards of the arms are $r_{i:i\neq {*}}=0.05$ and $r^{*}=0.1$ and variances are set as $\sigma_{i:i\neq *}^{2}=0.25$ and $\sigma_{*}^{2}=0.7$. For each of these testbeds of $20-100$ arms, we report the cumulative regret averaged over $100$ independent runs. The horizon is set at $T=10^{5} + K_{20:100}^{3}$ timesteps. We report the performance of MOSS, TS and OCUCB who are the closest competitors of EUCBV over this uniform gap setup. From the results in Figure \ref{fig:3}, it is evident that the growth of regret for EUCBV  is much lower than that of TS, OCUCB and MOSS. Because of the poor performance of Bayes-UCB and KL-UCB-Gauss+ in the last two experiments we do not implement them in this setup.  Bayes-UCB and KL-UCB-Gauss+ are not feasible to be run over such a large horizon as these algorithms are extremely slow in their execution. Also in all the experiments with Gaussian distributions EUCBV significantly outperforms all the Bayesian algorithms.


